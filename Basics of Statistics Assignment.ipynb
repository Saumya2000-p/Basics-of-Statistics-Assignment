{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "### Basics of Statistics Assignment ###",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1.\tExplain the different types of data (qualitative and quantitative) and provide examples of each. Discuss nominal, ordinal, interval, and ratio scales.\n2.\tWhat are the measures of central tendency, and when should you use each? Discuss the mean, median, and mode with examples and situations where each is appropriate.\n3.\tExplain the concept of dispersion. How do variance and standard deviation measure the spread of data?\n4.\tWhat is a box plot, and what can it tell you about the distribution of data?\n5.\tDiscuss the role of random sampling in making inferences about populations.\t\n6.\tExplain the concept of skewness and its types. How does skewness affect the interpretation of data?\n7.\tWhat is the interquartile range (IQR), and how is it used to detect outliers?\n8.\tDiscuss the conditions under which the binomial distribution is used.\n9.\tExplain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).\n10.\tProvide a real-life example of a Poisson process and calculate the probability for a specific event.\n11.\tExplain what a random variable is and differentiate between discrete and continuous random variables.\n12.\tProvide an example dataset, calculate both covariance and correlation, and interpret the results.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer1. Explain the different types of data (qualitative and quantitative) and provide examples of each. Discuss nominal, ordinal, interval, and ratio scales.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Types of Data: Qualitative vs. Quantitative\nData can be classified into two broad categories: qualitative and quantitative. Understanding these helps to identify how data is measured, analyzed, and interpreted.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Qualitative Data (also called Categorical Data)\nQualitative data refers to data that describes attributes or characteristics. This type of data cannot be measured numerically but can be classified into categories or groups. Qualitative data answers questions like What type? or What category?.\n\nExamples of Qualitative Data:\n* Gender (Male, Female, Non-binary)\n* Eye Color (Blue, Brown, Green)\n* Customer Satisfaction (Satisfied, Neutral, Dissatisfied)\n* Types of Animals (Dog, Cat, Bird)\nQualitative data can be further divided into two types of scales:",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Quantitative Data (also called Numerical Data)\nQuantitative data represents quantities and can be measured or counted. This data answers questions like How many? or How much? Quantitative data is numerical and can be subjected to mathematical operations (addition, subtraction, etc.).\n\nExamples of Quantitative Data:\n* Age (e.g., 25 years)\n* Height (e.g., 180 cm)\n* Income (e.g., $50,000 per year)\n* Temperature (e.g., 20Â°C)\nQuantitative data can be broken down into discrete and continuous data:\n* Discrete Data: Countable (e.g., number of students in a class).\n* Continuous Data: Measurable and can take on any value within a given range (e.g., weight, height, temperature).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Scales of Measurement\nWhen discussing quantitative data, it's important to understand the different scales of measurement used to classify and quantify data. The four primary scales of measurement are nominal, ordinal, interval, and ratio.\n\n1. Nominal Scale\nThe nominal scale is the simplest level of measurement. It involves data that is categorized based on names, labels, or qualities. There is no inherent order or ranking in the categories; they are simply different from one another.\n\nCharacteristics:\n* Categories are mutually exclusive (each data point fits into only one category).\n* No ordering or ranking is possible.\n\nExamples:\n* Types of Fruit: Apple, Banana, Orange.\n* Colors: Red, Blue, Green.\n* Nationality: American, Canadian, French.\n\n2. Ordinal Scale\nThe ordinal scale involves data that can be ranked or ordered, but the intervals between the ranks are not necessarily equal. The order matters, but the exact difference between the ranks is unknown or not uniform.\n\nCharacteristics:\n* Data can be ordered (ranked) from least to greatest or vice versa.\n* The differences between ranks are not uniform.\n\nExamples:\n* Customer Satisfaction: Very Unsatisfied, Unsatisfied, Neutral, Satisfied, Very Satisfied.\n* Education Level: High School, Bachelor's Degree, Master's Degree, PhD.\n* Survey Rating: Poor, Average, Good, Excellent.\n\n3. Interval Scale\nThe interval scale includes data that is ordered, and the intervals between values are equal. However, it does not have a true zero point, meaning that zero does not represent a total absence of the attribute being measured.\n\nCharacteristics:\n* Data is ordered.\n* Equal intervals between measurements.\n* No true zero point (zero is arbitrary).\n\nExamples:\n* Temperature (Celsius or Fahrenheit): The difference between 20Â°C and 30Â°C is the same as between 30Â°C and 40Â°C, but 0Â°C does not represent \"no temperature.\"\n* IQ Scores: The difference between scores of 100 and 110 is the same as between 110 and 120, but 0 IQ is not an absolute absence of intelligence.\n\n4. Ratio Scale\nThe ratio scale is the highest level of measurement. It includes data that has all the properties of the other scales (ordered, equal intervals) and also features a true zero point, meaning zero indicates the complete absence of the attribute being measured.\n\nCharacteristics:\n* Data is ordered.\n* Equal intervals between measurements.\n* True zero point (indicating the absence of the quantity being measured).\n* Ratios are meaningful (e.g., twice as much, half as much).\n\nExamples:\n* Height: A person who is 0 cm tall has no height, and a person who is 200 cm tall has twice the height of a person who is 100 cm tall.\n* Weight: A weight of 0 kg means no weight, and a person weighing 80 kg weighs twice as much as a person weighing 40 kg.\n* Income: $0 means no income, and $200,000 is twice the income of $100,000.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Key Takeaways:\n* Qualitative data describes categories or qualities, whereas quantitative data involves numbers and can be measured.\n* Nominal and Ordinal scales are typically used for qualitative data, while Interval and Ratio scales are used for quantitative data.\n* Ratio scale is the most informative because it provides equal intervals and a true zero point, making it possible to perform a wider range of mathematical operations.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer2. What are the measures of central tendency, and when should you use each? Discuss the mean, median, and mode with examples and situations where each is appropriate.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Measures of Central Tendency\nThe measures of central tendency are statistical tools used to summarize a set of data by identifying the central point or typical value within a dataset. The three primary measures of central tendency are:\n1. Mean\n2. Median\n3. Mode\nEach of these measures provides a different way of identifying the \"center\" of a dataset, and their appropriateness depends on the nature of the data and the distribution.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Mean (Arithmetic Average)\nThe mean is the most commonly used measure of central tendency. It is calculated by adding up all the values in a dataset and then dividing by the number of values. The formula for the mean is:\n\nMean =âˆ‘X/ğ‘›\n \nWhere:\n* âˆ‘X is the sum of all data points.\n* ğ‘› is the number of data points.\nWhen to use the mean:\n* The mean is most appropriate when the data is symmetrically distributed (i.e., there are no extreme outliers) and the data is measured on an interval or ratio scale.\n* It is sensitive to extreme values (outliers), so if the dataset contains outliers or is skewed, the mean may not represent the \"center\" accurately.\n\nExample: Consider the ages of five people in a group: 22, 25, 30, 34, and 100.\nMean = 22+25+30+34+100/5 =211/5 =42.2\n\nHere, the mean is 42.2 years, but the value is heavily influenced by the outlier (100), making it an inaccurate representation of the central age for most of the group.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Median (Middle Value)\nThe median is the middle value in a dataset when it is ordered from smallest to largest. If the dataset contains an odd number of values, the median is the middle value. If the dataset contains an even number of values, the median is the average of the two middle values.\n\nWhen to use the median:\n* The median is preferred when the data is skewed or contains outliers, as it is not affected by extremely large or small values.\n* It is often used with ordinal data or interval/ratio data that is not symmetrically distributed.\n\nExample: Consider the same ages as above: 22, 25, 30, 34, and 100.\n* Ordered data: 22, 25, 30, 34, 100\n* Median = 30 (middle value)\n\nIn this case, the median of 30 years is a better representation of the typical age in the group because it is not skewed by the outlier (100).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "3. Mode (Most Frequent Value)\nThe mode is the value that appears most frequently in a dataset. A dataset may have:\n* One mode (unimodal),\n* Two modes (bimodal), or\n* More than two modes (multimodal). If no value repeats, the dataset is said to have no mode.\n\nWhen to use the mode:\n* The mode is most useful for categorical or nominal data, where you want to know the most frequent category or value.\n* It can also be useful for understanding the most common or frequent value in a dataset, regardless of the shape of the distribution.\n\nExample: Consider the following data set: 1, 2, 2, 3, 3, 3, 4, 5.\n* Mode = 3 (since 3 appears most frequently)\n\nIn this case, 3 is the mode because it appears more times than any other value in the dataset.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Example Scenarios:\nUsing the Mean: A teacher wants to calculate the average test score for a class. If the scores are relatively consistent and not skewed by extreme values (like a perfect score from one student and very low scores from others), the mean is a good choice.\n* Scores: 75, 80, 85, 90, 95\n* Mean = 75+80+85+90+95/5 =85\nUsing the Median: A housing market analyst is calculating the \"typical\" house price in a city. If a few mansions sell for millions while most houses sell for much less, the median will better represent the central price, as the mean could be skewed by the expensive houses.\n* House prices: $150,000, $160,000, $170,000, $180,000, $1,500,000\n* Median = $170,000\nUsing the Mode: A marketing researcher wants to know the most popular ice cream flavor in a survey of 100 customers. The mode will tell them which flavor is the most frequently chosen, regardless of the exact distribution of preferences.\n* Survey Responses: Chocolate, Vanilla, Vanilla, Strawberry, Chocolate, Chocolate\n* Mode = Chocolate (since it occurs most often)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Key Takeaways:\n* Mean is the most commonly used measure when the data is symmetric and does not have outliers.\n* Median is useful when the data is skewed or contains outliers, as it is not affected by extreme values.\n* Mode is useful for categorical or nominal data, and to understand the most common value in a dataset.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer3. Explain the concept of dispersion. How do variance and standard deviation measure the spread of data?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Dispersion: Understanding the Spread of Data\nDispersion refers to the extent to which data points in a dataset vary or spread out from the central value (usually the mean or median). In other words, dispersion measures how much the values differ from the central tendency (mean, median, or mode). It provides insights into the variability or spread of the data, helping to understand whether the data is tightly clustered around the center or widely spread out.\n\nKey measures of dispersion include range, variance, and standard deviation. Among these, variance and standard deviation are the most commonly used to quantify the spread of the data, especially in statistical analysis.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Range\nThe range is the simplest measure of dispersion and is defined as the difference between the largest and smallest values in a dataset. While it is easy to compute, the range can be heavily influenced by outliers and extreme values.\n    Range=MaximumÂ Valueâˆ’MinimumÂ Value\nLimitations of the Range:\n* Sensitive to outliers.\n* Does not give any information about how the data points are distributed between the minimum and maximum.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Variance\nVariance is a more comprehensive measure of dispersion that quantifies how much each data point in a dataset differs from the mean. It is calculated by taking the average of the squared differences between each data point and the mean. The variance is expressed in squared units (e.g., squared dollars, squared meters), which can sometimes make it harder to interpret directly.\n\nFormula for Variance\n* For a population (Ïƒ2): ğœ2= âˆ‘(ğ‘‹ğ‘–âˆ’ğœ‡)2/ğ‘\n\nFor a sample (ğ‘ 2): ğ‘ 2= âˆ‘(ğ‘‹ğ‘–âˆ’ğ‘‹Ë‰)2/ğ‘›âˆ’1\n\nWhere:\n\n* ğ‘‹ğ‘– is each individual data point.\n* ğœ‡(or XË‰) is the mean of the population (or sample).\n* ğ‘(or ğ‘›) is the number of data points (for population or sample).\n* The squared differences are summed, and then divided by the total number of data points (or one less than the sample size, in the case of sample variance).\n\nInterpretation of Variance:\n* A high variance means that the data points are widely spread out from the mean.\n* A low variance means that the data points are closely clustered around the mean.\n\nExample: Consider the following two datasets:\n* Dataset 1: 10, 12, 14\n* Dataset 2: 1, 10, 19\nBoth datasets have the same mean (12), but the variance will be different because the spread of values is different in each set.\n\nVariance Calculation for Dataset 1:\n* Mean = 12\n* Squared differences from the mean:\n(10âˆ’12)2 =4, (12âˆ’12)2 =0, (14âˆ’12)2 =4\n* Variance = 4+0+4/3 =2.67\n\nVariance Calculation for Dataset 2:\n* Mean = 12\n* Squared differences from the mean:\n(1âˆ’12)2 =121, (10âˆ’12)2 =4, (19âˆ’12)2 =49\n* Variance = 121+4+49/3 =58\nThe second dataset has a higher variance, indicating that its values are more spread out from the mean.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "3. Standard Deviation\nStandard deviation is the square root of the variance. It is the most commonly used measure of dispersion because it is in the same unit as the original data, making it easier to interpret and understand in context. Unlike variance, which is in squared units, the standard deviation is expressed in the original units of measurement (e.g., dollars, centimeters).\n\nFormula for Standard Deviation\n* For a population (Ïƒ): ğœ= Nâˆ‘(Xiâˆ’Î¼)2/N\n* For a sample (ğ‘ ): ğ‘ =âˆ‘(ğ‘‹ğ‘–âˆ’ğ‘‹Ë‰)2/ğ‘›âˆ’1\n \nInterpretation of Standard Deviation:\n* A small standard deviation indicates that the data points are closely clustered around the mean.\n* A large standard deviation indicates that the data points are widely spread out from the mean.\n\nExample: Using the previous dataset examples:\n* Dataset 1: 10, 12, 14 â€” Variance = 2.67, so Standard Deviation = 2.67â‰ˆ1.63\n* Dataset 2: 1, 10, 19 â€” Variance = 58, so Standard Deviation = 58â‰ˆ7.62\nAs we can see, Dataset 2 has a higher standard deviation, indicating more spread or variability.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "How Variance and Standard Deviation Measure the Spread of Data\nBoth variance and standard deviation provide an understanding of how much the data points deviate from the central value (the mean). However, they differ in terms of interpretability:\n* Variance gives us an idea of the average squared deviation from the mean. However, since it is in squared units, it is often not as intuitive or directly comparable to the original data.\n* Standard deviation, being the square root of variance, is in the same units as the data itself, making it more interpretable. It directly represents the average distance of data points from the mean, providing a more intuitive measure of spread.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "When to Use Variance vs. Standard Deviation\n* Variance is typically used in theoretical statistics, particularly in calculating models and deriving statistical properties (e.g., in ANOVA, regression, and hypothesis testing).\n* Standard deviation is more commonly used in practical applications, particularly when you need to communicate the spread of data in understandable terms. It is the more \"user-friendly\" measure, as it is in the original units of measurement.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary: Key Points\n* Variance gives a measure of how spread out the values are from the mean, but in squared units, making it less intuitive.\n* Standard deviation is the square root of variance, offering a more intuitive measure of the spread in the original units of the data.\nBoth variance and standard deviation are essential tools for understanding the variability of data, and their use depends on whether you need a more theoretical measure (variance) or a more practical, interpretable measure (standard deviation).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer4. What is a box plot, and what can it tell you about the distribution of data?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Box Plot: A Visual Summary of Data Distribution\nA box plot (also called a box-and-whisker plot) is a powerful graphical tool used to display the distribution of a dataset. It provides a concise summary of a datasetâ€™s central tendency, spread, and variability, as well as highlights potential outliers. A box plot visually shows key aspects of the distribution using a box and whiskers, allowing you to quickly assess the shape, spread, and skewness of the data.\n\nKey Components of a Box Plot\nA box plot typically consists of the following components:\n1. Minimum: The smallest value in the dataset, excluding outliers.\n2. First Quartile (Q1): The 25th percentile of the data, also known as the lower quartile. It represents the point below which 25% of the data fall.\n3. Median (Q2): The 50th percentile or the middle value of the dataset, dividing the data into two equal halves.\n4. Third Quartile (Q3): The 75th percentile of the data, also known as the upper quartile. It represents the point below which 75% of the data fall.\n5. Maximum: The largest value in the dataset, excluding outliers.\n6. Interquartile Range (IQR): The distance between the first quartile (Q1) and the third quartile (Q3), i.e.,IQR=ğ‘„3âˆ’ğ‘„1. It represents the middle 50% of the data.\nThe plot itself consists of:\n* A box that spans from Q1 to Q3.\n* A line (whisker) extending from Q1 to the minimum and from Q3 to the maximum (excluding outliers).\n* A line inside the box representing the median.\nOutliers\nOutliers are typically defined as values that are:\n* Lower than ğ‘„1âˆ’1.5Ã—IQR.\n* Higher than ğ‘„3+1.5Ã—IQR.\nThese outliers are often represented by individual points (sometimes dots or asterisks) that are outside the whiskers.\n\nHow to Read a Box Plot\nLetâ€™s break down what a box plot can tell you about the data:\n1. Central Tendency\nThe median (Q2) is the central line inside the box. It tells you the middle value of the dataset and is a good indicator of the dataset's central tendency.\n* Symmetric Distribution: If the median is approximately in the middle of the box, the distribution is likely symmetric.\n* Skewed Distribution: If the median is closer to either the Q1 or Q3, it suggests the data is skewed:\n* Right Skew (Positive Skew): Median is closer to Q1, and the right whisker is longer.\n* Left Skew (Negative Skew): Median is closer to Q3, and the left whisker is longer.\n2. Spread and Variability\nThe box (from Q1 to Q3) and the whiskers indicate the spread or variability of the data.\n* The IQR (the distance between Q1 and Q3) represents the middle 50% of the data and gives an idea of how spread out the central portion of the data is.\n* Whiskers show the range of the data outside the IQR, extending to the minimum and maximum values, unless outliers are present.\n3. Outliers\nOutliers are data points that lie beyond the whiskers of the box plot. These are typically values that are significantly higher or lower than the rest of the data. Outliers can indicate:\n* Errors or anomalies in the data.\n* Interesting or exceptional cases that are worth investigating further.\n4. Skewness\nThe box plot can visually show whether the data is skewed:\n* Right Skew: If the right whisker is longer than the left whisker (with a median closer to Q1), the distribution has a rightward tail, indicating a positive skew.\n* Left Skew: If the left whisker is longer than the right whisker (with a median closer to Q3), the distribution has a leftward tail, indicating a negative skew.\n5. Symmetry\nA symmetric box plot, where the median is equidistant from Q1 and Q3, suggests that the data distribution is likely normal or close to it.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Example of a Box Plot\nConsider the following data set:\nData: 1, 3, 4, 5, 5, 6, 7, 8, 8, 9, 10, 12, 15, 16, 20\n\nTo construct a box plot, you would calculate:\n* Q1: 4 (25th percentile)\n* Median (Q2): 8 (50th percentile)\n* Q3: 12 (75th percentile)\n* IQR: ğ‘„3âˆ’ğ‘„1=12âˆ’4=8\n* Minimum: 1\n* Maximum: 20\n\nNow, imagine the box plot:\n* The box spans from Q1 = 4 to Q3 = 12.\n* The median is at 8, represented by a line inside the box.\n* The whiskers extend from 1 (minimum) to 20 (maximum).\n* If there were any outliers (e.g., values beyond ğ‘„1âˆ’1.5Ã—IQR or ğ‘„3+1.5Ã—IQR, they would be marked individually.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Key Insights from Box Plot:\n1. Distribution Shape:\n* If the whiskers are approximately equal length, the data is roughly symmetric.\n* If one whisker is longer, the data is skewed in that direction (right or left).\n2. Spread of Data:\n The width of the box and the length of the whiskers tell you about the spread of the data. A wider box or longer whiskers indicate more variability in the data.\n3. Outliers:\n Outliers will appear as individual points beyond the whiskers and should be investigated further. They may indicate errors, anomalies, or special cases.\n4. Central Tendency:\n The median gives you the middle value of the dataset, which is especially useful when comparing distributions across multiple groups.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "When to Use a Box Plot\n* Comparing Multiple Groups: Box plots are especially useful when comparing distributions between multiple groups or categories. Each group gets its own box plot, allowing you to visually compare the central tendency, spread, and outliers across groups.\n* Identifying Outliers: If you are interested in identifying unusual data points (outliers), box plots make it easy to spot these values.\n* Assessing Data Distribution: Box plots are helpful for assessing whether the data is symmetric, skewed, or has heavy tails, which can guide decisions about statistical methods or transformations.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary of What a Box Plot Can Tell You:\n* Central Tendency: The median gives you the central value of the dataset.\n* Spread: The box and whiskers give insight into the data's variability and range.\n* Outliers: Points outside the whiskers indicate potential outliers.\n* Skewness: The relative lengths of the whiskers can indicate whether the data is skewed.\nIn essence, a box plot is a great tool for summarizing a datasetâ€™s distribution, highlighting outliers, and comparing groups.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer5. Discuss the role of random sampling in making inferences about populations.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "The Role of Random Sampling in Making Inferences About Populations\nRandom sampling is a fundamental concept in statistics, especially when making inferences about a population based on a sample. The idea is that by selecting a sample randomly from a population, we can make unbiased and reliable estimates about the population as a whole. Hereâ€™s why random sampling is so critical in the process of making inferences:",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Representativeness of the Sample\nThe primary goal of random sampling is to ensure that the sample is representative of the broader population. When we randomly select participants or data points, every individual in the population has an equal chance of being included in the sample. This minimizes the risk of bias that could occur if certain individuals or subgroups were systematically overrepresented or underrepresented.\n* Example: Imagine you want to know the average height of students in a school. If you randomly select a group of students from various grades, genders, and ethnic backgrounds, the sample is more likely to reflect the diversity of the entire student body, leading to a more accurate estimate of the population's average height.\nWithout random sampling, thereâ€™s a risk that the sample might not accurately reflect the population, leading to biased results. For instance, if we only sampled students from a basketball team, the average height we calculate would likely be much higher than the average height for the entire school.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Generalization to the Population\nOne of the primary purposes of random sampling is to generalize the findings from the sample to the broader population. This is the foundation of statistical inference, which allows researchers to make conclusions about the entire population based on the sample data.\n* Example: Suppose a survey is conducted using a random sample of 1,000 voters in a country to predict how the entire population might vote in an upcoming election. If the sample is random, the results can be generalized with a certain level of confidence (usually expressed in terms of a confidence interval).\nThis generalization is valid because random sampling helps ensure that the sample reflects the characteristics of the population, allowing researchers to apply sample findings to the whole population.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "3. Reducing Bias and Ensuring Unbiased Estimations\nRandom sampling is key to reducing bias in statistical estimates. Bias refers to systematic errors that consistently push estimates away from the true population value. By using random sampling, every possible sample of a given size has an equal chance of being selected, which helps avoid any systematic errors that could arise from selective sampling methods.\n* Example: If we want to estimate the average income of people in a city, but we only sample individuals who are known to have high-paying jobs, we would have a biased sample. The average income we calculate would likely be much higher than the true average for the entire city. A random sample, on the other hand, would include people from all income groups, providing a more accurate estimate.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "4. Enabling Statistical Analysis and Confidence Intervals\nRandom sampling allows us to use statistical theory to make inferences about population parameters (such as the population mean, proportion, or variance) and to calculate confidence intervals. These intervals provide a range of values within which the true population parameter is likely to fall, based on the sample data.\n* Example: If a random sample of 500 households shows an average annual income of $50,000 with a standard deviation of $10,000, we can calculate a confidence interval (e.g., 95%) that estimates where the true population mean income likely lies. The ability to compute such intervals is possible because random sampling ensures the sample is a reliable estimate of the population.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "5. Enabling Hypothesis Testing\nRandom sampling is also crucial for conducting hypothesis tests, which allow researchers to assess whether there is enough evidence in the sample data to support or reject a hypothesis about the population. Since random sampling ensures that the sample is not biased, the statistical tests conducted on this sample have a valid foundation.\n* Example: If researchers want to test whether a new drug is effective at reducing blood pressure, they would randomly assign participants to either a treatment group or a control group. Random assignment helps ensure that the groups are comparable at the start of the experiment, reducing potential biases and ensuring that any observed differences in blood pressure are due to the drug and not some other factor.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "6. Law of Large Numbers and Reducing Sampling Error\nThe Law of Large Numbers states that as the sample size increases, the sample mean (or other statistics) will tend to approach the population mean. In the context of random sampling, this means that larger random samples are more likely to provide accurate and stable estimates of population parameters.\n* Example: If you randomly sample 10 people from a population and calculate their average income, the result will likely differ from the true population mean. However, if you increase the sample size to 1,000, the sample mean will likely be much closer to the true population mean. This happens because larger random samples tend to reduce sampling error, the natural variation that arises due to chance.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "7. Ensuring Valid Statistical Models\nMany statistical methods and models, such as regression analysis, ANOVA, or machine learning algorithms, rely on the assumption that the sample is randomly selected. If the data is not randomly sampled, the conclusions drawn from these models may be invalid or misleading. Random sampling ensures that these models are applied to data that can be generalized to the broader population.\n* Example: In a study predicting student performance based on factors like study hours, socioeconomic status, and prior academic achievement, random sampling ensures that the relationships identified in the model are not due to biases in who is included in the sample.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "8. Preventing Confounding Variables\nIn observational studies, where random assignment to treatments or conditions is not possible, random sampling helps mitigate the impact of confounding variablesâ€”factors that might influence both the independent and dependent variables. By ensuring that the sample is randomly selected, researchers reduce the likelihood that confounding variables will systematically distort the relationship between the variables being studied.\n* Example: In a study exploring the relationship between exercise and heart health, random sampling ensures that other factors like age, diet, and genetic predispositions donâ€™t disproportionately affect the outcome.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Conclusion\nRandom sampling is the cornerstone of statistical inference because it allows researchers to make valid, unbiased inferences about a population based on a sample. By ensuring that each member of the population has an equal chance of being selected, random sampling:\n* Provides a representative sample.\n* Reduces the risk of bias and confounding.\n* Enables generalization to the population.\n* Facilitates statistical analyses like hypothesis testing, confidence intervals, and regression models.\nIn summary, random sampling ensures that conclusions drawn from sample data are accurate, reliable, and applicable to the population as a whole. Without random sampling, the validity of statistical conclusions would be compromised, and inferences about the population would be less trustworthy.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer6. Explain the concept of skewness and its types. How does skewness affect the interpretation of data?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Skewness refers to the asymmetry in a data distribution. It indicates whether the data is symmetrical or has a longer tail on one side. There are three types:\n1. Right Skew (Positive Skew): The right tail is longer, and the mean is greater than the median (e.g., income distribution).\n2. Left Skew (Negative Skew): The left tail is longer, and the mean is less than the median (e.g., age at retirement).\n3. Symmetric: The distribution is balanced, with no skew, meaning the mean equals the median (e.g., normal distribution).\n\nHow Skewness Affects Interpretation:\n* Mean is sensitive to skewness, and can be misleading in skewed data.\n* Median is a better measure of central tendency when data is skewed.\n* Skewness can affect the spread (variance) and shape of the data, influencing the choice of statistical methods.\n* Data transformations (e.g., log transformation) can sometimes help reduce skewness.\n\nIn summary, skewness affects how we interpret data and choose appropriate statistical methods, especially when data is not symmetrically distributed.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer7. What is the interquartile range (IQR), and how is it used to detect outliers?",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Interquartile Range (IQR)\nThe Interquartile Range (IQR) is a measure of statistical dispersion, or how spread out the data is. It specifically represents the range between the first quartile (Q1) and the third quartile (Q3) of a dataset, encompassing the middle 50% of the data.\n* Q1 (first quartile): The value below which 25% of the data fall (the 25th percentile).\n* Q3 (third quartile): The value below which 75% of the data fall (the 75th percentile).\n* IQR is calculated as:IQR=ğ‘„3âˆ’ğ‘„1\n\nThe IQR helps to summarize the spread of the central 50% of the data, focusing on the middle portion and excluding extreme values (outliers).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Using the IQR to Detect Outliers\nOutliers are data points that fall significantly outside the normal range of the rest of the data. The IQR can be used to identify these outliers with the following steps:\n1. Calculate the IQR:\n* Find Q1 and Q3 of the dataset.\n* Compute the IQR: IQR=ğ‘„3âˆ’ğ‘„1.\n2. Determine the outlier thresholds:\n* Lower threshold: ğ‘„1âˆ’1.5Ã—IQR\n* Upper threshold: ğ‘„3+1.5Ã—IQR\nAny data points that fall below the lower threshold or above the upper threshold are considered outliers.\n3. Identify outliers:\n* Outliers are data points that fall outside the range of [ğ‘„1âˆ’1.5Ã—IQR,ğ‘„3+1.5Ã—IQR].",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Example:\nGiven the dataset:\nData: 1, 3, 4, 5, 6, 7, 8, 8, 9, 12, 15, 16, 20\n1. Calculate Q1 and Q3:\n* Q1 = 4 (25th percentile)\n* Q3 = 12 (75th percentile)\n* IQR = 12âˆ’4=8\n2. Determine the thresholds:\n*Lower threshold = 4âˆ’1.5Ã—8=âˆ’8\n* Upper threshold = 12+1.5Ã—8=24\n3. Identify outliers:\n* Any data points below -8 or above 24 are outliers.\n* Since all data points are between 1 and 20, there are no outliers in this case.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary\n* IQR measures the spread of the middle 50% of the data.\n* Outliers are values that fall 1.5 times the IQR below Q1 or above Q3.\n* The IQR is a robust measure for detecting outliers because it is not affected by extreme values in the data.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer8. Discuss the conditions under which the binomial distribution is used.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "The binomial distribution is used when:\n1. Fixed number of trials (ğ‘›): The experiment is repeated a set number of times.\n2. Two outcomes per trial: Each trial has only two possible outcomes, typically \"success\" and \"failure.\"\n3. Constant probability of success (ğ‘): The probability of success is the same for each trial.\n4. Independent trials: The outcome of one trial does not affect the others.\nFor example, flipping a fair coin 10 times is a binomial distribution, where each flip has two outcomes (heads or tails), a constant probability of 0.5 for heads, and independent flips. The probability of getting exactly ğ‘˜ successes (e.g., heads) in ğ‘› trials can be calculated using the binomial formula.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer9. Explain the properties of the normal distribution and the empirical rule (68-95-99.7 rule).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Properties of the Normal Distribution\nThe normal distribution is a continuous probability distribution that is symmetric and bell-shaped. It is widely used in statistics because many natural phenomena and measurement errors follow this distribution. The properties of the normal distribution are as follows:\n\n1. Symmetry:\n* The normal distribution is perfectly symmetric about its mean (ğœ‡). This means the left half of the distribution is a mirror image of the right half.\n2. Bell-shaped curve:\n*The distribution follows a bell-shaped curve, with the highest point at the mean, and the probability of values decreases as you move further away from the mean in either direction.\n3. Mean, Median, and Mode:\n* In a normal distribution, the mean, median, and mode are all equal and located at the center of the distribution.\n4. Defined by Two Parameters:\n* The normal distribution is fully described by two parameters:\nMean (ğœ‡): The central location of the distribution.\nStandard deviation (ğœ): The spread or dispersion of the distribution.\n* The larger the standard deviation, the wider and flatter the curve; the smaller the standard deviation, the narrower and taller the curve.\n5. Asymptotic:\n* The tails of the normal distribution curve approach the horizontal axis but never touch it. This means that there are always small probabilities of extreme values, but the likelihood of observing values far from the mean diminishes as you move further out.\n6. Empirical Probability:\n* The total area under the normal curve equals 1, representing the total probability of all possible outcomes.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "The Empirical Rule (68-95-99.7 Rule)\nThe Empirical Rule describes how data in a normal distribution is spread around the mean. It states that:\n\n1. 68% of the data falls within 1 standard deviation of the mean (ğœ‡Â±ğœ).\n2. 95% of the data falls within 2 standard deviations of the mean (ğœ‡Â±2ğœ).\n3. 99.7% of the data falls within 3 standard deviations of the mean (ğœ‡Â±3ğœ).\n\nThese percentages are useful for understanding the spread of data in a normal distribution and can be used to estimate the likelihood of observing values within certain ranges.\nVisual Representation:\n* 68%: Between ğœ‡âˆ’ğœ and ğœ‡+ğœ\n* 95%: Between ğœ‡âˆ’2ğœ and ğœ‡+2ğœ\n* 99.7%: Between ğœ‡âˆ’3ğœ and ğœ‡+3ğœ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary of Key Points:\n* Normal distribution is symmetric, bell-shaped, and described by the mean and standard deviation.\n* The Empirical Rule (68-95-99.7 rule) states:\n* 68% of data is within 1 standard deviation of the mean.\n* 95% is within 2 standard deviations.\n* 99.7% is within 3 standard deviations.\n\nThis rule is particularly helpful for estimating probabilities and understanding the spread of data in a normal distribution.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer10. Provide a real-life example of a Poisson process and calculate the probability for a specific event.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Real-life Example of a Poisson Process\nA Poisson process is a statistical model that describes the occurrence of events happening randomly and independently over time or space, with a known average rate (Î», lambda). The Poisson distribution can be used to model events that happen at a constant average rate, and where events do not occur in clusters but rather independently.\n\nExample: Customer Arrivals at a Bank\nConsider a bank where customers arrive at a service counter. Suppose that, on average, 5 customers arrive at the counter per hour. The number of customers arriving is independent of one another, and the arrivals are spread out over time.\n\nThis scenario follows a Poisson process because:\n* The events (customer arrivals) occur randomly over time.\n* The average rate of customer arrivals (ğœ†) is known (5 customers per hour).\n* The arrivals are independent (the arrival of one customer does not affect the next).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Poisson Distribution Formula\nThe probability of observing exactly k events in a fixed interval of time (or space) is given by the Poisson distribution formula:\n\nğ‘ƒ(ğ‘‹=ğ‘˜)=ğœ†ğ‘˜ğ‘’âˆ’ğœ†/ğ‘˜!\n\nWhere:\n* ğ‘ƒ(ğ‘‹=ğ‘˜) is the probability of exactly k events occurring.\n* ğœ† is the average rate of events per interval (mean).\n* ğ‘˜ is the number of events you're interested in.\n* ğ‘’ is Euler's number (ğ‘’â‰ˆ2.71828).",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Example Calculation: Probability of Exactly 3 Customers Arriving in 1 Hour\nLetâ€™s say you want to calculate the probability that exactly 3 customers arrive at the bank in 1 hour, given that the average arrival rate is 5 customers per hour.\n\n* ğœ†=5 (the average rate of customer arrivals per hour).\n* ğ‘˜=3 (we are interested in the probability of 3 customers arriving).\nWe apply the Poisson formula:\n ğ‘ƒ(ğ‘‹=3)=53ğ‘’âˆ’5/3!\n \n1. First, calculate the individual parts:\n* 53=125\n* ğ‘’âˆ’5â‰ˆ0.006737 (this is the exponential part).\n* 3!=6 (factorial of 3).\n2. Now plug these values into the formula:\nğ‘ƒ(ğ‘‹=3)=125Ã—0.006737/6\nğ‘ƒ(ğ‘‹=3)=0.843625/6â‰ˆ0.1406\n\nSo, the probability of exactly 3 customers arriving in 1 hour is approximately 0.1406 or 14.06%.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary\nIn this example, the Poisson distribution helps to model the number of customers arriving at the bank, and the calculated probability shows how likely it is that exactly 3 customers will arrive in a given 1-hour period. The Poisson process is widely used in scenarios like modeling customer arrivals, call center traffic, webpage visits, and more, where events happen independently and at a consistent average rate over time or space.   ",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer11. Explain what a random variable is and differentiate between discrete and continuous random variables.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "What is a Random Variable?\nA random variable is a variable whose value is determined by the outcome of a random event or experiment. It represents a numerical outcome that can vary, depending on the random process or experiment being conducted.\n* A random variable can take on different values, and each value is associated with a certain probability.\n* Random variables are often used in probability theory and statistics to quantify uncertainty and model real-world phenomena.\nThere are two types of random variables: discrete and continuous.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "1. Discrete Random Variables\nA discrete random variable is one that can take on a finite or countably infinite number of distinct values. These values can often be listed, counted, or enumerated. Discrete random variables are typically associated with events that involve counting.\n\nCharacteristics of Discrete Random Variables:\n* They take on distinct, separate values (e.g., whole numbers).\n* The possible outcomes can be listed, and there is no intermediate value between two outcomes.\n* They often represent counts of objects or events.\nExamples of Discrete Random Variables:\n* Number of heads in 5 coin flips: The possible values are 0, 1, 2, 3, 4, or 5.\n* Number of students in a classroom: The values could be 0, 1, 2, 3, ..., up to the maximum number of students, but not any fractional or decimal number.\n* Number of cars passing a toll booth in an hour: Possible values are 0, 1, 2, ..., but not fractions like 1.5 cars.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "2. Continuous Random Variables\nA continuous random variable is one that can take on any value within a certain range or interval. These variables are often associated with measurements that can take on an infinite number of possible values within a given range.\n\nCharacteristics of Continuous Random Variables:\n* They take on values from a continuous range, meaning there are infinitely many possible values.\n* These values are not countable, and they can take on decimal or fractional values.\n* They often represent measurements such as length, time, temperature, or weight.\nExamples of Continuous Random Variables:\n* Height of a person: Can take any value within a range (e.g., 5.4 feet, 5.45 feet, 5.456 feet, etc.).\n* Time taken for a runner to complete a race: Could be 10.25 seconds, 10.256 seconds, or any other value within a range.\n* Temperature: A continuous variable, as it could be 22.3Â°C, 22.31Â°C, 22.315Â°C, etc.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary\n* Random Variable: A variable whose value is determined by the outcome of a random event.\n* Discrete Random Variable: Takes distinct, countable values (e.g., number of heads in coin flips, number of students).\n* Continuous Random Variable: Takes any value within a range and can be measured with high precision (e.g., height, temperature, time).\nThe distinction between discrete and continuous random variables is important because it determines how probability distributions are represented and calculated.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Answer12. Provide an example dataset, calculate both covariance and correlation, and interpret the results.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "andom Variable Example: Hours Studied vs. Exam Scores\nHereâ€™s a simple dataset:\n\nStudent\tHours Studied (X)\tExam Score (Y)\nA\t         2\t               55\nB\t         3\t               60\nC\t         4\t               65\nD\t         5\t               70\nE\t         6\t               75",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Covariance Calculation:\nCovariance shows how two variables change together.\n\n1. Step 1: Find the mean of ğ‘‹ and ğ‘Œ:\n* Mean of ğ‘‹ = 4, Mean of ğ‘Œ = 65.\n2. Step 2: Calculate the covariance formula:\n Cov(ğ‘‹,ğ‘Œ)=1/ğ‘›âˆ’1âˆ‘(ğ‘‹ğ‘–âˆ’ğ‘‹Ë‰)(ğ‘Œğ‘–âˆ’ğ‘ŒË‰)=12.5\n\nInterpretation: A positive covariance (12.5) indicates that as study hours increase, exam scores tend to increase too.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Correlation Calculation:\nCorrelation measures the strength of the relationship between the two variables.\n\n1. Step 1: Calculate standard deviations of ğ‘‹ and ğ‘Œ:\n* Standard deviation of ğ‘‹ â‰ˆ 1.58, of ğ‘Œ â‰ˆ 7.91.\n2. Step 2: Calculate the correlation:\n* Correlation(ğ‘‹,ğ‘Œ)=Cov(ğ‘‹,ğ‘Œ)/ğœğ‘‹ğœğ‘Œ=1\n\nInterpretation: A correlation of 1 means there is a perfect positive relationship â€” as study hours go up, exam scores increase perfectly in sync.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "Summary:\n* Covariance (12.5) shows a positive relationship: more hours studied â†’ higher exam scores.\n* Correlation (1) shows a perfect linear relationship between the two.",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}